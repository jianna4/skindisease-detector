{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9154979,
          "sourceType": "datasetVersion",
          "datasetId": 5530427
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "skindisease2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jianna4/skindisease-detector/blob/main/skindisease2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "syedalinaqvi_augmented_skin_conditions_image_dataset_path = kagglehub.dataset_download('syedalinaqvi/augmented-skin-conditions-image-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "BYF4uf2yeyzD"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "import os\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-23T16:09:47.213722Z",
          "iopub.execute_input": "2025-11-23T16:09:47.214026Z",
          "iopub.status.idle": "2025-11-23T16:09:47.489281Z",
          "shell.execute_reply.started": "2025-11-23T16:09:47.214002Z",
          "shell.execute_reply": "2025-11-23T16:09:47.488709Z"
        },
        "id": "EN5xXkcyeyzG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import Input, regularizers\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Conv2D, MaxPooling2D, Flatten, Dropout ,BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "import os\n",
        "import json\n",
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomBrightness\n",
        "from tensorflow.keras import Sequential\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-23T16:09:47.490491Z",
          "iopub.execute_input": "2025-11-23T16:09:47.490834Z",
          "iopub.status.idle": "2025-11-23T16:10:03.522754Z",
          "shell.execute_reply.started": "2025-11-23T16:09:47.490806Z",
          "shell.execute_reply": "2025-11-23T16:10:03.522117Z"
        },
        "id": "ioYqHWbqeyzH",
        "outputId": "481aa512-813c-42af-ef3c-3cfc6d6217bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-11-23 16:09:48.871136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763914189.062165      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763914189.115571      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your dataset directory\n",
        "dataset_dir = '/kaggle/input/augmented-skin-conditions-image-dataset/Skin_Conditions'#insert yours\n",
        "\n",
        "# Load the dataset\n",
        "dataset = image_dataset_from_directory(\n",
        "    dataset_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-23T16:10:03.523438Z",
          "iopub.execute_input": "2025-11-23T16:10:03.523877Z",
          "iopub.status.idle": "2025-11-23T16:10:06.733274Z",
          "shell.execute_reply.started": "2025-11-23T16:10:03.52385Z",
          "shell.execute_reply": "2025-11-23T16:10:06.732694Z"
        },
        "id": "egTIcdIaeyzI",
        "outputId": "1cda4838-512a-460c-e818-e6d7d7f5cb65"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Found 2394 files belonging to 6 classes.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "I0000 00:00:1763914205.207147      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset\n",
        "train_size = 0.8\n",
        "total_batches = tf.data.experimental.cardinality(dataset).numpy()\n",
        "train_batches = int(train_size * total_batches)\n",
        "train_dataset = dataset.take(train_batches)\n",
        "test_dataset = dataset.skip(train_batches)\n",
        "val_size = 0.1\n",
        "val_batches = int(val_size * total_batches)\n",
        "validation_dataset = test_dataset.take(val_batches)\n",
        "test_dataset = test_dataset.skip(val_batches)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-23T16:10:06.734883Z",
          "iopub.execute_input": "2025-11-23T16:10:06.73509Z",
          "iopub.status.idle": "2025-11-23T16:10:06.749267Z",
          "shell.execute_reply.started": "2025-11-23T16:10:06.735074Z",
          "shell.execute_reply": "2025-11-23T16:10:06.74875Z"
        },
        "id": "Zg_RLTj2eyzJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "data_augmentation = Sequential([\n",
        "    RandomFlip(\"horizontal\"),\n",
        "    RandomRotation(0.1),\n",
        "    RandomZoom(0.1),\n",
        "    RandomBrightness(0.1)\n",
        "])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-23T16:10:06.749795Z",
          "iopub.execute_input": "2025-11-23T16:10:06.749976Z",
          "iopub.status.idle": "2025-11-23T16:10:06.816007Z",
          "shell.execute_reply.started": "2025-11-23T16:10:06.749962Z",
          "shell.execute_reply": "2025-11-23T16:10:06.815422Z"
        },
        "id": "L9p9KSvceyzK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#applying the augmentation only on training dataset\n",
        "def augment(images, labels):\n",
        "    images = data_augmentation(images, training=True)\n",
        "    return images, labels\n",
        "\n",
        "train_dataset = train_dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-23T16:10:06.816663Z",
          "iopub.execute_input": "2025-11-23T16:10:06.81687Z",
          "iopub.status.idle": "2025-11-23T16:10:07.032303Z",
          "shell.execute_reply.started": "2025-11-23T16:10:06.816845Z",
          "shell.execute_reply": "2025-11-23T16:10:07.031712Z"
        },
        "id": "w-rNYEgfeyzL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Prefetch for speed\n",
        "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = validation_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-23T16:10:07.033089Z",
          "iopub.execute_input": "2025-11-23T16:10:07.033533Z",
          "iopub.status.idle": "2025-11-23T16:10:07.040804Z",
          "shell.execute_reply.started": "2025-11-23T16:10:07.033507Z",
          "shell.execute_reply": "2025-11-23T16:10:07.040121Z"
        },
        "id": "A61CPxa2eyzL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained ResNet50 without the top classifier layers\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base initially\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build custom head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)       # Converts features to 1D vector no need for flatten\n",
        "x = Dense(1024, activation='relu')(x) # Fully connected layer\n",
        "x = Dropout(0.5)(x)                   # Prevent overfitting\n",
        "predictions = Dense(6, activation='softmax')(x)  # 6 classes\n",
        "\n",
        "# Final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "#the FUNCTIONAL API (Model ) allows complex architecture withmultiple inputand output"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-23T16:10:07.041546Z",
          "iopub.execute_input": "2025-11-23T16:10:07.041762Z",
          "iopub.status.idle": "2025-11-23T16:10:09.492766Z",
          "shell.execute_reply.started": "2025-11-23T16:10:07.041738Z",
          "shell.execute_reply": "2025-11-23T16:10:09.492189Z"
        },
        "id": "GtcuIdGxeyzM",
        "outputId": "864cea6e-597d-48d7-9db1-1d28bfa7c260"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "the suquential model was:\n",
        "model = tf.keras.models.Sequential([\n",
        "     # Block 1\n",
        "    Conv2D(32, (3, 3), padding='same', activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.0001),\n",
        "           input_shape=(224,224,3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    # Block 2\n",
        "    Conv2D(64, (3, 3), padding='same', activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.0001)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    # Block 3\n",
        "    Conv2D(128, (3, 3), padding='same', activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.0001)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(128, activation='relu'),\n",
        "    #Dropout(0.4),                 # VERY IMPORTANT\n",
        "    Dense(6, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "bJ4FW9vmeyzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- CALLBACKS ---\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=8,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,        # reduce LR by 50%\n",
        "    patience=2,        # if val_loss doesn't improve for 2 epochs\n",
        "    min_lr=1e-10,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10,       # ðŸ‘ˆ PUT EPOCHS HERE\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop, reduce_lr]    # ðŸ‘ˆ ADD CALLBACKS HERE\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-23T16:10:09.493552Z",
          "iopub.execute_input": "2025-11-23T16:10:09.493803Z"
        },
        "id": "0t3H40OFeyzO",
        "outputId": "dbed693b-9d2a-40de-ee86-96e7d1295c4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f'Test Loss: {test_loss}')\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "\n",
        "# Save the model after evaluation\n",
        "\n",
        "model.save(\"your_model.keras\",include_optimizer=False)\n",
        "\n",
        "print(\"Model saved as '/kaggle/working/your_model.keras\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "t8OVOLaAeyzP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Save the training history to a JSON file\n",
        "history_dict = history.history\n",
        "with open('training_history.json', 'w') as f:\n",
        "    json.dump(history_dict, f)\n",
        "print(\"Training history saved as training_history.json\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Lncd5LGFeyzQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions and create classification report\n",
        "y_true, y_pred = [], []\n",
        "for images, labels in test_dataset:\n",
        "    preds = model.predict(images)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=dataset.class_names))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)\n",
        "\n",
        "# Function to Plot Confusion Matrix\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), ha=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plot_confusion_matrix(cm, classes=dataset.class_names, title='Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot accuracy and loss curves\n",
        "def plot_training_curves(history):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(loc='upper left')\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to plot training curves\n",
        "plot_training_curves(history_dict)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "9xiFD8dJeyzQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class_names = [\n",
        "    'Acne',\n",
        "    'Carcinoma',\n",
        "    'Eczema',\n",
        "    'Keratosis',\n",
        "    'Milia',\n",
        "    'Rosacea'\n",
        "]\n",
        "\n",
        "def plot_random_images(test_dataset, model, class_names, num_images=9):\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for image_batch, label_batch in test_dataset.take(1):\n",
        "        predictions = model.predict(image_batch)\n",
        "        predicted_labels = np.argmax(predictions, axis=1)\n",
        "        indices = np.random.choice(len(image_batch), num_images, replace=False)\n",
        "\n",
        "        for idx, ax in enumerate(axes):\n",
        "            img = image_batch[indices[idx]].numpy().astype(np.uint8)\n",
        "            true_label = label_batch[indices[idx]].numpy()\n",
        "            pred_label = predicted_labels[indices[idx]]\n",
        "\n",
        "            ax.imshow(img)\n",
        "            ax.axis('off')\n",
        "\n",
        "            true_label_name = class_names[true_label]\n",
        "            pred_label_name = class_names[pred_label]\n",
        "            title_color = 'green' if true_label == pred_label else 'red'\n",
        "            ax.set_title(f\"True: {true_label_name}\\nPred: {pred_label_name}\", color=title_color, fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_random_images(test_dataset, model, class_names)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "92-q7uQmeyzR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Function to plot ROC curve for each class\n",
        "def plot_roc_curve(fpr, tpr, auc, class_names):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# Convert labels to one-hot encoding for ROC curve\n",
        "y_true_one_hot = []\n",
        "y_pred_probs = []\n",
        "\n",
        "for images, labels in test_dataset:\n",
        "    preds = model.predict(images)\n",
        "    y_true_one_hot.extend(labels.numpy())\n",
        "    y_pred_probs.extend(preds)\n",
        "\n",
        "y_true_one_hot = label_binarize(y_true_one_hot, classes=np.arange(len(dataset.class_names)))\n",
        "y_pred_probs = np.array(y_pred_probs)\n",
        "\n",
        "# Compute ROC curve and ROC AUC for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(len(dataset.class_names)):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true_one_hot[:, i], y_pred_probs[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curves for each class\n",
        "for i in range(len(dataset.class_names)):\n",
        "    plot_roc_curve(fpr[i], tpr[i], roc_auc[i], dataset.class_names)\n",
        "\n",
        "# Optionally, plot a macro-average ROC curve\n",
        "fpr[\"macro\"], tpr[\"macro\"], _ = roc_curve(y_true_one_hot.ravel(), y_pred_probs.ravel())\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "plot_roc_curve(fpr[\"macro\"], tpr[\"macro\"], roc_auc[\"macro\"], [\"Macro Average\"])\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "5fGmtldTeyzR"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}